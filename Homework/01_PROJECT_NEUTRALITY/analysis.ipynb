{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "579b567a-2b80-4bf1-8cc1-c514da76ca50",
   "metadata": {},
   "source": [
    "# (ADA) Homework 1: Scoring the Language Model Olympics\n",
    "\n",
    "---\n",
    "\n",
    "By the end of this homework, we expect you to be able to:\n",
    "\n",
    "- Load data and handle data using pandas;\n",
    "- Navigate the documentation of Python packages by yourself;\n",
    "- Filter and tidy up noisy real-world datasets;\n",
    "- Aggregate your data in different (and hopefully helpful) ways;\n",
    "- Create meaningful visualizations to analyze the data;\n",
    "- Communicate your findings in a clear and concise manner\n",
    "\n",
    "---\n",
    "\n",
    "**Important Dates.**\n",
    "\n",
    "- Homework release: Fri 04 Oct 2024\n",
    "- Homework due: Sat 18 Oct 2024, 23:59\n",
    "- Grade release: Mon 04 Nov 2024\n",
    "\n",
    "**Some rules**\n",
    "\n",
    "- You are allowed to use any built-in Python library that comes with Anaconda. If you want to use an external library, you may do so, but must justify your choice.\n",
    "- Make sure you use the data folder provided in the repository in read-only mode. (Or alternatively, be sure you don’t change any of the files.)\n",
    "- Be sure to provide a concise textual description of your thought process, the assumptions you made, the solution you implemented, and explanations for your answers. A notebook that only has code cells will not suffice. To avoid confusion: use short comments for longer code answers.\n",
    "- For questions containing the /Discuss:/ prefix, answer not with code, but with a textual explanation (in markdown).\n",
    "- Back up any hypotheses and claims with data, since this is an important aspect of the course.\n",
    "- Please write all your comments in English, and use meaningful variable names in your code. Your repo should have a single notebook (plus the required data files) in the master/main branch. If there are multiple notebooks present, we will not grade anything.\n",
    "- We will not run your notebook for you! Rather, we will grade it as is, which means that only the results contained in your evaluated code cells will be considered, and we will not see the results in unevaluated code cells. Thus, be sure to hand in a fully-run and evaluated notebook. In order to check whether everything looks as intended, you can check the rendered notebook on the GitHub website once you have pushed your solution there.\n",
    "- In continuation to the previous point, interactive plots, such as those generated using the ‘plotly’ package, should be strictly avoided! Make sure to print results and/or dataframes that confirm you have properly addressed the task.\n",
    "\n",
    "**A Note on using Language Models (LMs)**\n",
    "\n",
    "If you try hard enough, you will likely get away with cheating. Fortunately, our job is not to police, but rather to educate! So, please consider the following:\n",
    "- Presumably, you are taking this course to learn something! LMs are not always right ([they often fail in silly ways](https://community.openai.com/t/why-9-11-is-larger-than-9-9-incredible/869824/4)). This course should prepare you to detect when they are wrong!\n",
    "- Some of the TAs on this course literally published many works on detecting machine-generated text.\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f85896e-c0ae-4ae3-af41-46149faa2278",
   "metadata": {},
   "source": [
    "## Context\n",
    "\n",
    "Context\n",
    "AI is booming! Newspapers, influencers, and your relatives all agree that AI is important. But while almost everyone agrees that AI is the future, much is unclear about what that future looks like…\n",
    "\n",
    "Freshly graduated from the EPFL, you are hired by the Swiss government to advise on a large-scale “AI integration” initiative code-named **\"NEUTRALITY\"** (Navigating Efficient Upgrades Through Robust Artificial Learning Integration Techniques Yearly). Convinced by the stunning progress in language modeling, the government would like to battle the growing shortages in the education sector by using LMs. Your job description: investigate which LMs might be best suited!\n",
    "\n",
    "You are given the results of three LMs on the [“Massive Multitask Language Understanding (MMLU)”](https://arxiv.org/abs/2009.03300) dataset to compare. This famous dataset consists of 57 subjects with multiple-choice questions, covering diverse subjects like mathematics, computer science, history, and law. Most providers of state-of-the-art LMs use this dataset to showcase the versatility of their latest models. Unfortunately, Horta-Ribeiro, the intern responsible for collecting the results, didn’t take EPFL’s famous ADA course. As a result, the collected datasets are slightly corrupted.\n",
    "\n",
    "### A very brief primer on Language Models\n",
    "Language models (LMs) are sophisticated statistical models designed to understand and generate human-like text. At their core, LMs are trained to predict the most likely continuation of a given input text. For example, given the input \"The cat sat on the,\" an LM might predict \"mat\" as a likely continuation.\n",
    "LMs are trained on vast text samples from various sources, including books, websites, and social media. This extensive training allows them to capture patterns and relationships in language, enabling them to generate coherent and contextually appropriate text across a wide range of topics and styles.\n",
    "\n",
    "While LMs can produce text that appears to be written by intelligent humans, it's important to note that their capabilities can diverge from human intelligence in unexpected ways. They may sometimes generate factually incorrect information or struggle with complex reasoning tasks.\n",
    "\n",
    "Two key concepts in understanding LMs are:\n",
    "1. **Tokens**: LMs process text using \"tokens\" rather than individual characters. Tokens can be words, parts of words, or punctuation marks. For example, the sentence \"I love AI!\" might be tokenized as [\"I\", \"love\", \"AI\", \"!\"]. Tokenization is the first step in both training and using an LM.\n",
    "2. **Context**: The input text provided to an LM is called the \"context.\" This context informs the model's predictions or generations. A longer or more specific context often leads to more accurate and relevant outputs.\n",
    "\n",
    "[See: Wikipedia entry on language models](https://en.wikipedia.org/wiki/Large_language_model)\n",
    "\n",
    "###  Files for this assignment\n",
    "This assignment is divided into three tasks, each of which should bring you a step closer to providing a recommendation toward project NEUTRALITY’s objectives:\n",
    "\n",
    "- **Task 1**: Inspecting the results and getting your first model ranking\n",
    "- **Task 2**: Inspecting the underlying data used to generate the results for possible biases\n",
    "- **Task 3**: Learning about tokens and providing a final recommendation\n",
    "\n",
    "\n",
    "```\n",
    "📁 PROJECT_NEUTRALITY\n",
    "│\n",
    "├── 📄 analysis.ipynb (the file you're currently reading!)\n",
    "├── 📄 requirements.txt (install into your environment)\n",
    "│\n",
    "├── 📁 task_1\n",
    "├── 📁 task_2\n",
    "└── 📁 task_2.5\n",
    "```   \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "378f2a5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting jupyter>=1.0.0 (from -r requirements.txt (line 1))\n",
      "  Using cached jupyter-1.1.1-py2.py3-none-any.whl.metadata (2.0 kB)\n",
      "Requirement already satisfied: matplotlib>=3.8.0 in c:\\users\\hp\\anaconda3\\envs\\ada\\lib\\site-packages (from -r requirements.txt (line 2)) (3.9.2)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\hp\\anaconda3\\envs\\ada\\lib\\site-packages (from -r requirements.txt (line 3)) (1.26.4)\n",
      "Requirement already satisfied: pandas>=2.1.1 in c:\\users\\hp\\anaconda3\\envs\\ada\\lib\\site-packages (from -r requirements.txt (line 4)) (2.2.2)\n",
      "Requirement already satisfied: scipy>=1.13 in c:\\users\\hp\\anaconda3\\envs\\ada\\lib\\site-packages (from -r requirements.txt (line 5)) (1.13.1)\n",
      "Requirement already satisfied: seaborn>=0.12.2 in c:\\users\\hp\\anaconda3\\envs\\ada\\lib\\site-packages (from -r requirements.txt (line 6)) (0.13.2)\n",
      "Collecting tiktoken>=0.7.0 (from -r requirements.txt (line 7))\n",
      "  Downloading tiktoken-0.8.0-cp311-cp311-win_amd64.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: notebook in c:\\users\\hp\\anaconda3\\envs\\ada\\lib\\site-packages (from jupyter>=1.0.0->-r requirements.txt (line 1)) (6.5.7)\n",
      "Collecting jupyter-console (from jupyter>=1.0.0->-r requirements.txt (line 1))\n",
      "  Downloading jupyter_console-6.6.3-py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: nbconvert in c:\\users\\hp\\anaconda3\\envs\\ada\\lib\\site-packages (from jupyter>=1.0.0->-r requirements.txt (line 1)) (7.10.0)\n",
      "Requirement already satisfied: ipykernel in c:\\users\\hp\\anaconda3\\envs\\ada\\lib\\site-packages (from jupyter>=1.0.0->-r requirements.txt (line 1)) (6.28.0)\n",
      "Requirement already satisfied: ipywidgets in c:\\users\\hp\\anaconda3\\envs\\ada\\lib\\site-packages (from jupyter>=1.0.0->-r requirements.txt (line 1)) (8.1.5)\n",
      "Requirement already satisfied: jupyterlab in c:\\users\\hp\\anaconda3\\envs\\ada\\lib\\site-packages (from jupyter>=1.0.0->-r requirements.txt (line 1)) (4.2.5)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\hp\\anaconda3\\envs\\ada\\lib\\site-packages (from matplotlib>=3.8.0->-r requirements.txt (line 2)) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\hp\\anaconda3\\envs\\ada\\lib\\site-packages (from matplotlib>=3.8.0->-r requirements.txt (line 2)) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\hp\\anaconda3\\envs\\ada\\lib\\site-packages (from matplotlib>=3.8.0->-r requirements.txt (line 2)) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\hp\\anaconda3\\envs\\ada\\lib\\site-packages (from matplotlib>=3.8.0->-r requirements.txt (line 2)) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\hp\\anaconda3\\envs\\ada\\lib\\site-packages (from matplotlib>=3.8.0->-r requirements.txt (line 2)) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\hp\\anaconda3\\envs\\ada\\lib\\site-packages (from matplotlib>=3.8.0->-r requirements.txt (line 2)) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\hp\\anaconda3\\envs\\ada\\lib\\site-packages (from matplotlib>=3.8.0->-r requirements.txt (line 2)) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\hp\\anaconda3\\envs\\ada\\lib\\site-packages (from matplotlib>=3.8.0->-r requirements.txt (line 2)) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\hp\\anaconda3\\envs\\ada\\lib\\site-packages (from pandas>=2.1.1->-r requirements.txt (line 4)) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\hp\\anaconda3\\envs\\ada\\lib\\site-packages (from pandas>=2.1.1->-r requirements.txt (line 4)) (2023.3)\n",
      "Collecting regex>=2022.1.18 (from tiktoken>=0.7.0->-r requirements.txt (line 7))\n",
      "  Downloading regex-2024.9.11-cp311-cp311-win_amd64.whl.metadata (41 kB)\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\users\\hp\\anaconda3\\envs\\ada\\lib\\site-packages (from tiktoken>=0.7.0->-r requirements.txt (line 7)) (2.32.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\hp\\anaconda3\\envs\\ada\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=3.8.0->-r requirements.txt (line 2)) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\hp\\anaconda3\\envs\\ada\\lib\\site-packages (from requests>=2.26.0->tiktoken>=0.7.0->-r requirements.txt (line 7)) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hp\\anaconda3\\envs\\ada\\lib\\site-packages (from requests>=2.26.0->tiktoken>=0.7.0->-r requirements.txt (line 7)) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\hp\\anaconda3\\envs\\ada\\lib\\site-packages (from requests>=2.26.0->tiktoken>=0.7.0->-r requirements.txt (line 7)) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hp\\anaconda3\\envs\\ada\\lib\\site-packages (from requests>=2.26.0->tiktoken>=0.7.0->-r requirements.txt (line 7)) (2024.8.30)\n",
      "Requirement already satisfied: comm>=0.1.1 in c:\\users\\hp\\anaconda3\\envs\\ada\\lib\\site-packages (from ipykernel->jupyter>=1.0.0->-r requirements.txt (line 1)) (0.2.1)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in c:\\users\\hp\\anaconda3\\envs\\ada\\lib\\site-packages (from ipykernel->jupyter>=1.0.0->-r requirements.txt (line 1)) (1.6.7)\n",
      "Requirement already satisfied: ipython>=7.23.1 in c:\\users\\hp\\anaconda3\\envs\\ada\\lib\\site-packages (from ipykernel->jupyter>=1.0.0->-r requirements.txt (line 1)) (8.27.0)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in c:\\users\\hp\\anaconda3\\envs\\ada\\lib\\site-packages (from ipykernel->jupyter>=1.0.0->-r requirements.txt (line 1)) (7.4.9)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in c:\\users\\hp\\anaconda3\\envs\\ada\\lib\\site-packages (from ipykernel->jupyter>=1.0.0->-r requirements.txt (line 1)) (5.7.2)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in c:\\users\\hp\\anaconda3\\envs\\ada\\lib\\site-packages (from ipykernel->jupyter>=1.0.0->-r requirements.txt (line 1)) (0.1.6)\n",
      "Requirement already satisfied: nest-asyncio in c:\\users\\hp\\anaconda3\\envs\\ada\\lib\\site-packages (from ipykernel->jupyter>=1.0.0->-r requirements.txt (line 1)) (1.6.0)\n",
      "Requirement already satisfied: psutil in c:\\users\\hp\\anaconda3\\envs\\ada\\lib\\site-packages (from ipykernel->jupyter>=1.0.0->-r requirements.txt (line 1)) (5.9.0)\n",
      "Requirement already satisfied: pyzmq>=24 in c:\\users\\hp\\anaconda3\\envs\\ada\\lib\\site-packages (from ipykernel->jupyter>=1.0.0->-r requirements.txt (line 1)) (24.0.1)\n",
      "Requirement already satisfied: tornado>=6.1 in c:\\users\\hp\\anaconda3\\envs\\ada\\lib\\site-packages (from ipykernel->jupyter>=1.0.0->-r requirements.txt (line 1)) (6.4.1)\n",
      "Requirement already satisfied: traitlets>=5.4.0 in c:\\users\\hp\\anaconda3\\envs\\ada\\lib\\site-packages (from ipykernel->jupyter>=1.0.0->-r requirements.txt (line 1)) (5.14.3)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.12 in c:\\users\\hp\\anaconda3\\envs\\ada\\lib\\site-packages (from ipywidgets->jupyter>=1.0.0->-r requirements.txt (line 1)) (4.0.13)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.12 in c:\\users\\hp\\anaconda3\\envs\\ada\\lib\\site-packages (from ipywidgets->jupyter>=1.0.0->-r requirements.txt (line 1)) (3.0.13)\n",
      "Requirement already satisfied: prompt-toolkit>=3.0.30 in c:\\users\\hp\\anaconda3\\envs\\ada\\lib\\site-packages (from jupyter-console->jupyter>=1.0.0->-r requirements.txt (line 1)) (3.0.43)\n",
      "Requirement already satisfied: pygments in c:\\users\\hp\\anaconda3\\envs\\ada\\lib\\site-packages (from jupyter-console->jupyter>=1.0.0->-r requirements.txt (line 1)) (2.15.1)\n",
      "Requirement already satisfied: async-lru>=1.0.0 in c:\\users\\hp\\anaconda3\\envs\\ada\\lib\\site-packages (from jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 1)) (2.0.4)\n",
      "Requirement already satisfied: httpx>=0.25.0 in c:\\users\\hp\\anaconda3\\envs\\ada\\lib\\site-packages (from jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 1)) (0.27.0)\n",
      "Requirement already satisfied: jinja2>=3.0.3 in c:\\users\\hp\\anaconda3\\envs\\ada\\lib\\site-packages (from jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 1)) (3.1.4)\n",
      "Requirement already satisfied: jupyter-lsp>=2.0.0 in c:\\users\\hp\\anaconda3\\envs\\ada\\lib\\site-packages (from jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 1)) (2.2.0)\n",
      "Requirement already satisfied: jupyter-server<3,>=2.4.0 in c:\\users\\hp\\anaconda3\\envs\\ada\\lib\\site-packages (from jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 1)) (2.14.1)\n",
      "Requirement already satisfied: jupyterlab-server<3,>=2.27.1 in c:\\users\\hp\\anaconda3\\envs\\ada\\lib\\site-packages (from jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 1)) (2.27.3)\n",
      "Requirement already satisfied: notebook-shim>=0.2 in c:\\users\\hp\\anaconda3\\envs\\ada\\lib\\site-packages (from jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 1)) (0.2.3)\n",
      "Requirement already satisfied: setuptools>=40.1.0 in c:\\users\\hp\\anaconda3\\envs\\ada\\lib\\site-packages (from jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 1)) (72.1.0)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\hp\\anaconda3\\envs\\ada\\lib\\site-packages (from nbconvert->jupyter>=1.0.0->-r requirements.txt (line 1)) (4.12.3)\n",
      "Requirement already satisfied: bleach!=5.0.0 in c:\\users\\hp\\anaconda3\\envs\\ada\\lib\\site-packages (from nbconvert->jupyter>=1.0.0->-r requirements.txt (line 1)) (4.1.0)\n",
      "Requirement already satisfied: defusedxml in c:\\users\\hp\\anaconda3\\envs\\ada\\lib\\site-packages (from nbconvert->jupyter>=1.0.0->-r requirements.txt (line 1)) (0.7.1)\n",
      "Requirement already satisfied: jupyterlab-pygments in c:\\users\\hp\\anaconda3\\envs\\ada\\lib\\site-packages (from nbconvert->jupyter>=1.0.0->-r requirements.txt (line 1)) (0.1.2)\n",
      "Requirement already satisfied: markupsafe>=2.0 in c:\\users\\hp\\anaconda3\\envs\\ada\\lib\\site-packages (from nbconvert->jupyter>=1.0.0->-r requirements.txt (line 1)) (2.1.3)\n",
      "Requirement already satisfied: mistune<4,>=2.0.3 in c:\\users\\hp\\anaconda3\\envs\\ada\\lib\\site-packages (from nbconvert->jupyter>=1.0.0->-r requirements.txt (line 1)) (2.0.4)\n",
      "Requirement already satisfied: nbclient>=0.5.0 in c:\\users\\hp\\anaconda3\\envs\\ada\\lib\\site-packages (from nbconvert->jupyter>=1.0.0->-r requirements.txt (line 1)) (0.8.0)\n",
      "Requirement already satisfied: nbformat>=5.7 in c:\\users\\hp\\anaconda3\\envs\\ada\\lib\\site-packages (from nbconvert->jupyter>=1.0.0->-r requirements.txt (line 1)) (5.9.2)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in c:\\users\\hp\\anaconda3\\envs\\ada\\lib\\site-packages (from nbconvert->jupyter>=1.0.0->-r requirements.txt (line 1)) (1.5.0)\n",
      "Requirement already satisfied: tinycss2 in c:\\users\\hp\\anaconda3\\envs\\ada\\lib\\site-packages (from nbconvert->jupyter>=1.0.0->-r requirements.txt (line 1)) (1.2.1)\n",
      "Requirement already satisfied: argon2-cffi in c:\\users\\hp\\anaconda3\\envs\\ada\\lib\\site-packages (from notebook->jupyter>=1.0.0->-r requirements.txt (line 1)) (21.3.0)\n",
      "Requirement already satisfied: ipython-genutils in c:\\users\\hp\\anaconda3\\envs\\ada\\lib\\site-packages (from notebook->jupyter>=1.0.0->-r requirements.txt (line 1)) (0.2.0)\n",
      "Requirement already satisfied: Send2Trash>=1.8.0 in c:\\users\\hp\\anaconda3\\envs\\ada\\lib\\site-packages (from notebook->jupyter>=1.0.0->-r requirements.txt (line 1)) (1.8.2)\n",
      "Requirement already satisfied: terminado>=0.8.3 in c:\\users\\hp\\anaconda3\\envs\\ada\\lib\\site-packages (from notebook->jupyter>=1.0.0->-r requirements.txt (line 1)) (0.17.1)\n",
      "Requirement already satisfied: prometheus-client in c:\\users\\hp\\anaconda3\\envs\\ada\\lib\\site-packages (from notebook->jupyter>=1.0.0->-r requirements.txt (line 1)) (0.14.1)\n",
      "Requirement already satisfied: nbclassic>=0.4.7 in c:\\users\\hp\\anaconda3\\envs\\ada\\lib\\site-packages (from notebook->jupyter>=1.0.0->-r requirements.txt (line 1)) (1.1.0)\n",
      "Requirement already satisfied: webencodings in c:\\users\\hp\\anaconda3\\envs\\ada\\lib\\site-packages (from bleach!=5.0.0->nbconvert->jupyter>=1.0.0->-r requirements.txt (line 1)) (0.5.1)\n",
      "Requirement already satisfied: anyio in c:\\users\\hp\\anaconda3\\envs\\ada\\lib\\site-packages (from httpx>=0.25.0->jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 1)) (4.2.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\hp\\anaconda3\\envs\\ada\\lib\\site-packages (from httpx>=0.25.0->jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 1)) (1.0.2)\n",
      "Requirement already satisfied: sniffio in c:\\users\\hp\\anaconda3\\envs\\ada\\lib\\site-packages (from httpx>=0.25.0->jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 1)) (1.3.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\hp\\anaconda3\\envs\\ada\\lib\\site-packages (from httpcore==1.*->httpx>=0.25.0->jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 1)) (0.14.0)\n",
      "Requirement already satisfied: decorator in c:\\users\\hp\\anaconda3\\envs\\ada\\lib\\site-packages (from ipython>=7.23.1->ipykernel->jupyter>=1.0.0->-r requirements.txt (line 1)) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\hp\\anaconda3\\envs\\ada\\lib\\site-packages (from ipython>=7.23.1->ipykernel->jupyter>=1.0.0->-r requirements.txt (line 1)) (0.19.1)\n",
      "Requirement already satisfied: stack-data in c:\\users\\hp\\anaconda3\\envs\\ada\\lib\\site-packages (from ipython>=7.23.1->ipykernel->jupyter>=1.0.0->-r requirements.txt (line 1)) (0.2.0)\n",
      "Requirement already satisfied: typing-extensions>=4.6 in c:\\users\\hp\\anaconda3\\envs\\ada\\lib\\site-packages (from ipython>=7.23.1->ipykernel->jupyter>=1.0.0->-r requirements.txt (line 1)) (4.11.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\hp\\anaconda3\\envs\\ada\\lib\\site-packages (from ipython>=7.23.1->ipykernel->jupyter>=1.0.0->-r requirements.txt (line 1)) (0.4.6)\n",
      "Requirement already satisfied: entrypoints in c:\\users\\hp\\anaconda3\\envs\\ada\\lib\\site-packages (from jupyter-client>=6.1.12->ipykernel->jupyter>=1.0.0->-r requirements.txt (line 1)) (0.4)\n",
      "Requirement already satisfied: platformdirs>=2.5 in c:\\users\\hp\\anaconda3\\envs\\ada\\lib\\site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel->jupyter>=1.0.0->-r requirements.txt (line 1)) (3.10.0)\n",
      "Requirement already satisfied: pywin32>=300 in c:\\users\\hp\\anaconda3\\envs\\ada\\lib\\site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel->jupyter>=1.0.0->-r requirements.txt (line 1)) (305.1)\n",
      "Requirement already satisfied: jupyter-events>=0.9.0 in c:\\users\\hp\\anaconda3\\envs\\ada\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 1)) (0.10.0)\n",
      "Requirement already satisfied: jupyter-server-terminals>=0.4.4 in c:\\users\\hp\\anaconda3\\envs\\ada\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 1)) (0.4.4)\n",
      "Requirement already satisfied: overrides>=5.0 in c:\\users\\hp\\anaconda3\\envs\\ada\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 1)) (7.4.0)\n",
      "Requirement already satisfied: pywinpty>=2.0.1 in c:\\users\\hp\\anaconda3\\envs\\ada\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 1)) (2.0.10)\n",
      "Requirement already satisfied: websocket-client>=1.7 in c:\\users\\hp\\anaconda3\\envs\\ada\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 1)) (1.8.0)\n",
      "Requirement already satisfied: argon2-cffi-bindings in c:\\users\\hp\\anaconda3\\envs\\ada\\lib\\site-packages (from argon2-cffi->notebook->jupyter>=1.0.0->-r requirements.txt (line 1)) (21.2.0)\n",
      "Requirement already satisfied: babel>=2.10 in c:\\users\\hp\\anaconda3\\envs\\ada\\lib\\site-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 1)) (2.11.0)\n",
      "Requirement already satisfied: json5>=0.9.0 in c:\\users\\hp\\anaconda3\\envs\\ada\\lib\\site-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 1)) (0.9.6)\n",
      "Requirement already satisfied: jsonschema>=4.18.0 in c:\\users\\hp\\anaconda3\\envs\\ada\\lib\\site-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 1)) (4.19.2)\n",
      "Requirement already satisfied: fastjsonschema in c:\\users\\hp\\anaconda3\\envs\\ada\\lib\\site-packages (from nbformat>=5.7->nbconvert->jupyter>=1.0.0->-r requirements.txt (line 1)) (2.16.2)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\hp\\anaconda3\\envs\\ada\\lib\\site-packages (from prompt-toolkit>=3.0.30->jupyter-console->jupyter>=1.0.0->-r requirements.txt (line 1)) (0.2.5)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\hp\\anaconda3\\envs\\ada\\lib\\site-packages (from beautifulsoup4->nbconvert->jupyter>=1.0.0->-r requirements.txt (line 1)) (2.5)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in c:\\users\\hp\\anaconda3\\envs\\ada\\lib\\site-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel->jupyter>=1.0.0->-r requirements.txt (line 1)) (0.8.3)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\hp\\anaconda3\\envs\\ada\\lib\\site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 1)) (23.1.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\hp\\anaconda3\\envs\\ada\\lib\\site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 1)) (2023.7.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\hp\\anaconda3\\envs\\ada\\lib\\site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 1)) (0.30.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\hp\\anaconda3\\envs\\ada\\lib\\site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 1)) (0.10.6)\n",
      "Requirement already satisfied: python-json-logger>=2.0.4 in c:\\users\\hp\\anaconda3\\envs\\ada\\lib\\site-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 1)) (2.0.7)\n",
      "Requirement already satisfied: pyyaml>=5.3 in c:\\users\\hp\\anaconda3\\envs\\ada\\lib\\site-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 1)) (6.0.1)\n",
      "Requirement already satisfied: rfc3339-validator in c:\\users\\hp\\anaconda3\\envs\\ada\\lib\\site-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 1)) (0.1.4)\n",
      "Requirement already satisfied: rfc3986-validator>=0.1.1 in c:\\users\\hp\\anaconda3\\envs\\ada\\lib\\site-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 1)) (0.1.1)\n",
      "Requirement already satisfied: cffi>=1.0.1 in c:\\users\\hp\\anaconda3\\envs\\ada\\lib\\site-packages (from argon2-cffi-bindings->argon2-cffi->notebook->jupyter>=1.0.0->-r requirements.txt (line 1)) (1.16.0)\n",
      "Requirement already satisfied: executing in c:\\users\\hp\\anaconda3\\envs\\ada\\lib\\site-packages (from stack-data->ipython>=7.23.1->ipykernel->jupyter>=1.0.0->-r requirements.txt (line 1)) (0.8.3)\n",
      "Requirement already satisfied: asttokens in c:\\users\\hp\\anaconda3\\envs\\ada\\lib\\site-packages (from stack-data->ipython>=7.23.1->ipykernel->jupyter>=1.0.0->-r requirements.txt (line 1)) (2.0.5)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\hp\\anaconda3\\envs\\ada\\lib\\site-packages (from stack-data->ipython>=7.23.1->ipykernel->jupyter>=1.0.0->-r requirements.txt (line 1)) (0.2.2)\n",
      "Requirement already satisfied: pycparser in c:\\users\\hp\\anaconda3\\envs\\ada\\lib\\site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook->jupyter>=1.0.0->-r requirements.txt (line 1)) (2.21)\n",
      "Requirement already satisfied: fqdn in c:\\users\\hp\\anaconda3\\envs\\ada\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 1)) (1.5.1)\n",
      "Requirement already satisfied: isoduration in c:\\users\\hp\\anaconda3\\envs\\ada\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 1)) (20.11.0)\n",
      "Requirement already satisfied: jsonpointer>1.13 in c:\\users\\hp\\anaconda3\\envs\\ada\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 1)) (3.0.0)\n",
      "Requirement already satisfied: uri-template in c:\\users\\hp\\anaconda3\\envs\\ada\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 1)) (1.3.0)\n",
      "Requirement already satisfied: webcolors>=1.11 in c:\\users\\hp\\anaconda3\\envs\\ada\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 1)) (24.8.0)\n",
      "Requirement already satisfied: arrow>=0.15.0 in c:\\users\\hp\\anaconda3\\envs\\ada\\lib\\site-packages (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 1)) (1.3.0)\n",
      "Requirement already satisfied: types-python-dateutil>=2.8.10 in c:\\users\\hp\\anaconda3\\envs\\ada\\lib\\site-packages (from arrow>=0.15.0->isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 1)) (2.9.0.20240906)\n",
      "Using cached jupyter-1.1.1-py2.py3-none-any.whl (2.7 kB)\n",
      "Downloading tiktoken-0.8.0-cp311-cp311-win_amd64.whl (884 kB)\n",
      "   ---------------------------------------- 0.0/884.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 884.5/884.5 kB 5.7 MB/s eta 0:00:00\n",
      "Downloading regex-2024.9.11-cp311-cp311-win_amd64.whl (274 kB)\n",
      "Downloading jupyter_console-6.6.3-py3-none-any.whl (24 kB)\n",
      "Installing collected packages: regex, tiktoken, jupyter-console, jupyter\n",
      "Successfully installed jupyter-1.1.1 jupyter-console-6.6.3 regex-2024.9.11 tiktoken-0.8.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95ce4c12-9681-401e-9489-aa0765b19d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# please make sure you install the packages listed in the requirements.txt file in your environment!\n",
    "# using pip\n",
    "# pip install -r requirements.txt\n",
    "#\n",
    "# using Conda:\n",
    "# conda create --name <env_name> --file requirements.txt\n",
    "#\n",
    "# some basic imports\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "from scipy.stats import ttest_ind"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e62594ad-4f5f-4a46-80bc-deacf66b62e9",
   "metadata": {},
   "source": [
    "## Task 1 (18 points): What's in an average anyway?\n",
    "\n",
    "The files needed to complete task 1 can be found in the folder \"`data/task_1/`:\n",
    "```\n",
    "task_1/\n",
    "│\n",
    "├── mmlu_data/\n",
    "│   └── test.csv\n",
    "│\n",
    "└── lm_scores/\n",
    "    ├── lm_X.csv\n",
    "    ├── lm_Y.csv\n",
    "    └── lm_Z.csv\n",
    "```\n",
    "\n",
    "We will start by loading, (manually) inspecting, and cleaning the data. Although it doesn't seem \"glamorous\" (nor is it particularly fun...) - manually inspecting data is extremely important! In fact, it's one of the few things most AI and Data Science researchers agree on :). Next, we will take a first pass on ordering our Olympic podium between three LMs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8605646-79fa-4cb3-8137-b6951bd1e064",
   "metadata": {},
   "source": [
    "### 1.1 (1 pt)\n",
    " \n",
    "Load the subfiles contained in the `mmlu_data` and `lm_scores` folders into separate dataframes:\n",
    "- `df_test`\n",
    "- `df_x`\n",
    "- `df_y`\n",
    "- `df_z`\n",
    "\n",
    "for each, print their sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e6ce5e96-7de6-463d-a00b-6a4b2cfc8cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "task_folder = './task_1/'\n",
    "lm_scores_folder = './lm_scores/'\n",
    "mmlu_folder = './mmlu_data/'\n",
    "\n",
    "#mmlu_data import\n",
    "df_test = pd.read_csv(task_folder + mmlu_folder + 'test.csv')\n",
    "\n",
    "\n",
    "#lm_scores import\n",
    "df_x = pd.read_csv(task_folder + lm_scores_folder + 'lm_X.csv')\n",
    "df_y = pd.read_csv(task_folder + lm_scores_folder + 'lm_Y.csv')\n",
    "df_z = pd.read_csv(task_folder + lm_scores_folder + 'lm_Z.csv')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e4d77551",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>answer</th>\n",
       "      <th>subject</th>\n",
       "      <th>question_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Find the degree for the given field extension ...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>B</td>\n",
       "      <td>abstract algebra</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Let p = (1, 2, 5, 4)(2, 3) in S_5 . Find the i...</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "      <td>120</td>\n",
       "      <td>C</td>\n",
       "      <td>abstract algebra</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Find all zeros in the indicated finite field o...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0,1</td>\n",
       "      <td>0,4</td>\n",
       "      <td>D</td>\n",
       "      <td>abstract algebra</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Statement 1 | A factor group of a non-Abelian ...</td>\n",
       "      <td>True, True</td>\n",
       "      <td>False, False</td>\n",
       "      <td>True, False</td>\n",
       "      <td>False, True</td>\n",
       "      <td>B</td>\n",
       "      <td>abstract algebra</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Find the product of the given polynomials in t...</td>\n",
       "      <td>2x^2 + 5</td>\n",
       "      <td>6x^2 + 4x + 6</td>\n",
       "      <td>0</td>\n",
       "      <td>x^2 + 1</td>\n",
       "      <td>B</td>\n",
       "      <td>abstract algebra</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14037</th>\n",
       "      <td>What has been a central focus of religious tra...</td>\n",
       "      <td>Peace and harmony</td>\n",
       "      <td>Power and influence</td>\n",
       "      <td>Truth and love</td>\n",
       "      <td>Wisdom and ethics</td>\n",
       "      <td>A</td>\n",
       "      <td>world religions</td>\n",
       "      <td>14037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14038</th>\n",
       "      <td>To whom did ordinary folk appeal during a dro...</td>\n",
       "      <td>The Buddha</td>\n",
       "      <td>Laozi</td>\n",
       "      <td>The Queen Mother of the West</td>\n",
       "      <td>Confucius</td>\n",
       "      <td>C</td>\n",
       "      <td>world religions</td>\n",
       "      <td>14038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14039</th>\n",
       "      <td>The theological term homoousios means which o...</td>\n",
       "      <td>of a similar substance</td>\n",
       "      <td>of the same substance</td>\n",
       "      <td>of like substance</td>\n",
       "      <td>of human substance</td>\n",
       "      <td>B</td>\n",
       "      <td>world religions</td>\n",
       "      <td>14039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14040</th>\n",
       "      <td>According to the Japanese origin myth, who giv...</td>\n",
       "      <td>Es</td>\n",
       "      <td>Izanagi</td>\n",
       "      <td>Izanami</td>\n",
       "      <td>Kami</td>\n",
       "      <td>B</td>\n",
       "      <td>world religions</td>\n",
       "      <td>14040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14041</th>\n",
       "      <td>The numen of Augustus referred to which of th...</td>\n",
       "      <td>Divine power</td>\n",
       "      <td>Sexual virility</td>\n",
       "      <td>Military acumen</td>\n",
       "      <td>Philosophical intellect</td>\n",
       "      <td>A</td>\n",
       "      <td>world religions</td>\n",
       "      <td>14041</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14042 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                question  \\\n",
       "0      Find the degree for the given field extension ...   \n",
       "1      Let p = (1, 2, 5, 4)(2, 3) in S_5 . Find the i...   \n",
       "2      Find all zeros in the indicated finite field o...   \n",
       "3      Statement 1 | A factor group of a non-Abelian ...   \n",
       "4      Find the product of the given polynomials in t...   \n",
       "...                                                  ...   \n",
       "14037  What has been a central focus of religious tra...   \n",
       "14038   To whom did ordinary folk appeal during a dro...   \n",
       "14039   The theological term homoousios means which o...   \n",
       "14040  According to the Japanese origin myth, who giv...   \n",
       "14041   The numen of Augustus referred to which of th...   \n",
       "\n",
       "                            A                      B  \\\n",
       "0                           0                      4   \n",
       "1                           8                      2   \n",
       "2                           0                      1   \n",
       "3                  True, True           False, False   \n",
       "4                    2x^2 + 5          6x^2 + 4x + 6   \n",
       "...                       ...                    ...   \n",
       "14037       Peace and harmony    Power and influence   \n",
       "14038              The Buddha                  Laozi   \n",
       "14039  of a similar substance  of the same substance   \n",
       "14040                      Es                Izanagi   \n",
       "14041            Divine power        Sexual virility   \n",
       "\n",
       "                                  C                        D answer  \\\n",
       "0                                 2                        6      B   \n",
       "1                                24                      120      C   \n",
       "2                               0,1                      0,4      D   \n",
       "3                       True, False              False, True      B   \n",
       "4                                 0                  x^2 + 1      B   \n",
       "...                             ...                      ...    ...   \n",
       "14037                Truth and love        Wisdom and ethics      A   \n",
       "14038  The Queen Mother of the West                Confucius      C   \n",
       "14039             of like substance       of human substance      B   \n",
       "14040                       Izanami                     Kami      B   \n",
       "14041               Military acumen  Philosophical intellect      A   \n",
       "\n",
       "                subject  question_id  \n",
       "0      abstract algebra            0  \n",
       "1      abstract algebra            1  \n",
       "2      abstract algebra            2  \n",
       "3      abstract algebra            3  \n",
       "4      abstract algebra            4  \n",
       "...                 ...          ...  \n",
       "14037   world religions        14037  \n",
       "14038   world religions        14038  \n",
       "14039   world religions        14039  \n",
       "14040   world religions        14040  \n",
       "14041   world religions        14041  \n",
       "\n",
       "[14042 rows x 8 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1b82c3f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the size of the df_test dataset is 14042\n"
     ]
    }
   ],
   "source": [
    "print('the size of the df_test dataset is', df_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cc9148fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_id</th>\n",
       "      <th>result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Answer: B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13877</th>\n",
       "      <td>14037</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13878</th>\n",
       "      <td>14038</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13879</th>\n",
       "      <td>14039</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13880</th>\n",
       "      <td>14040</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13881</th>\n",
       "      <td>14041</td>\n",
       "      <td>Answer: A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13882 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       question_id     result\n",
       "0                0          B\n",
       "1                1          C\n",
       "2                2         D \n",
       "3                3         B \n",
       "4                4  Answer: B\n",
       "...            ...        ...\n",
       "13877        14037         A \n",
       "13878        14038          A\n",
       "13879        14039          B\n",
       "13880        14040          B\n",
       "13881        14041  Answer: A\n",
       "\n",
       "[13882 rows x 2 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9e9367b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the size of the df_x dataset is 13882\n"
     ]
    }
   ],
   "source": [
    "print('the size of the df_x dataset is',df_x.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "db923e47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_id</th>\n",
       "      <th>result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Answer: D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Answer: D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13973</th>\n",
       "      <td>14037</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13974</th>\n",
       "      <td>14038</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13975</th>\n",
       "      <td>14039</td>\n",
       "      <td>Answer: D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13976</th>\n",
       "      <td>14040</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13977</th>\n",
       "      <td>14041</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13978 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       question_id     result\n",
       "0                0  Answer: D\n",
       "1                1          D\n",
       "2                2  Answer: D\n",
       "3                3        NaN\n",
       "4                4          D\n",
       "...            ...        ...\n",
       "13973        14037         C \n",
       "13974        14038          D\n",
       "13975        14039  Answer: D\n",
       "13976        14040          B\n",
       "13977        14041         D \n",
       "\n",
       "[13978 rows x 2 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7e89d225",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the size of the df_y dataset is 13978\n"
     ]
    }
   ],
   "source": [
    "print('the size of the df_y dataset is', df_y.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "73935ad7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_id</th>\n",
       "      <th>result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Answer: B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13918</th>\n",
       "      <td>14037</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13919</th>\n",
       "      <td>14038</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13920</th>\n",
       "      <td>14039</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13921</th>\n",
       "      <td>14040</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13922</th>\n",
       "      <td>14041</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13923 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       question_id     result\n",
       "0                0          B\n",
       "1                1  Answer: B\n",
       "2                2          C\n",
       "3                3         B \n",
       "4                4          B\n",
       "...            ...        ...\n",
       "13918        14037          A\n",
       "13919        14038          A\n",
       "13920        14039          B\n",
       "13921        14040         B \n",
       "13922        14041          A\n",
       "\n",
       "[13923 rows x 2 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "00c8d9f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the size of the df_z dataset is 13923\n"
     ]
    }
   ],
   "source": [
    "print('the size of the df_z dataset is',df_z.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acbda57d-7df2-4e33-b31c-52bc0af6753e",
   "metadata": {},
   "source": [
    "### 1.2 (4 pt)\n",
    "Unfortunately, LMs don't always output the format we want. In the column `result`, the value should be one of A, B, C, or D. \n",
    "\n",
    "A. For each of the LM score dataframes, use a `value_counts()` operation and print the results. \n",
    "\n",
    "B. /Discuss:/ Inspect the results and describe the types of answer formats you see. Besides the \"expected\" case, you should be able to find at least four unexpected formats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "79936f23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the values for the dataset df_x are :\n",
      " result\n",
      "A                                                                                                                 2733\n",
      "A                                                                                                                 1657\n",
      "B                                                                                                                 1412\n",
      "Answer: A                                                                                                         1398\n",
      "C                                                                                                                 1134\n",
      "                                                                                                                  ... \n",
      "judicial activism, so the answer is A                                                                                1\n",
      "creating insurmountable obstacles to the founding of factions, so the answer is A                                    1\n",
      "A congressperson who retires to take a position teaching political science at a university, so the answer is A       1\n",
      "David Hume, so the answer is D                                                                                       1\n",
      "Brahminic orthodoxy, so the answer is A                                                                              1\n",
      "Name: count, Length: 145, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# A\n",
    "print(\"the values for the dataset df_x are :\\n\", pd.Series.value_counts(df_x['result']))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a56eee3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " the values for the dataset df_y are :\n",
      " result\n",
      "D                                                                                                2894\n",
      "Answer: D                                                                                        1718\n",
      "C                                                                                                1701\n",
      "B                                                                                                1240\n",
      "D                                                                                                1145\n",
      "                                                                                                 ... \n",
      "Where the energy of interaction between the atoms is at its minimum value, so the answer is A       1\n",
      "leaves more viable offspring than others of its species., so the answer is D                        1\n",
      "A and C only, so the answer is D                                                                    1\n",
      "ADP + P → ATP, so the answer is D                                                                   1\n",
      "Monoclonal antibodies, so the answer is C                                                           1\n",
      "Name: count, Length: 141, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\\n the values for the dataset df_y are :\\n\", pd.Series.value_counts(df_y['result']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ede3300d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " the values for the dataset df_z are :\n",
      " result\n",
      "D                                                                                   2257\n",
      "C                                                                                   2191\n",
      "B                                                                                   2127\n",
      "A                                                                                   2060\n",
      "Answer: D                                                                            777\n",
      "                                                                                    ... \n",
      "omission of a universal suffrage clause, so the answer is D                            1\n",
      "declare war, so the answer is D                                                        1\n",
      "state and local governments, by means of federal funding, so the answer is B           1\n",
      "less clearly identified with consistent political ideologies, so the answer is B       1\n",
      "Rahit, so the answer is B                                                              1\n",
      "Name: count, Length: 560, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\\n the values for the dataset df_z are :\\n\", pd.Series.value_counts(df_z['result']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "B - For the three datasets the expected results should be : A, B, C or D \n",
    "\n",
    "Beside these expected results, we can observe the following answer formats:\n",
    "+ a duplicate of the letter A, B, C or D. The result is detected as diffrent from the expected probably due to a diffrent format \n",
    "+ the result preceded by \" Answer : A \"\n",
    "+ preceded by text (either explanation or content) - \" ... , so the answer is A \"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c5551d-1968-427b-bdd6-51d996898e7c",
   "metadata": {},
   "source": [
    "### 1.3 (5 pt)\n",
    "Oh oh... That doesn't look great. Simply dropping all invalid answers seems overly wasteful, yet fixing all of these looks like a mess! Instead, let's focus for now on fixing just those answers of length < 10 characters that require only a single `str.replace()` operation. \n",
    "\n",
    "For example, if the answer looks like `--A--`, we could fix this by using the following simple function:\n",
    "\n",
    "```\n",
    "def clean_answer(s, pattern='-'):\n",
    "    return str(s).replace(pattern, '')\n",
    "\n",
    "dirty_answer = '--A--'\n",
    "clean_answer = clean_answer(dirty_answer)\n",
    "```\n",
    "\n",
    "A. Filter the three score dataframes to include only answers with less than 10 characters. Make a deep copy of the dataframes as you filter them.\n",
    "\n",
    "B. Modify the `clean_answer()` example function to clean the answers in the filtered data frames using the `apply()` functionality. Finally, make sure **all remaining answers are one of `A, B, C, or D`.**\n",
    "\n",
    "C. /Discuss:/ Compare the sizes of the original and filtered data frames. What do you see? Why might this be a problem?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "79daf47b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['', 'D']"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example=\"ANSWER: D\"\n",
    "\n",
    "example.split(\"ANSWER: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "aef1f933-20bf-426a-ac9d-a35e273b9bd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleaned df_x result\n",
      "A    5788\n",
      "B    2965\n",
      "C    2350\n",
      "D    2333\n",
      "Name: count, dtype: int64\n",
      "cleaned df_y result\n",
      "D    5757\n",
      "C    3242\n",
      "B    2519\n",
      "A    2033\n",
      "Name: count, dtype: int64\n",
      "cleaned df_z result\n",
      "D    3348\n",
      "C    3255\n",
      "B    3124\n",
      "A    3026\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# A\n",
    "df_x_less10 = df_x[df_x['result'].str.len() < 10].copy(deep=True)\n",
    "df_y_less10 = df_y[df_y['result'].str.len() < 10].copy(deep=True)\n",
    "df_z_less10 = df_z[df_z['result'].str.len() < 10].copy(deep=True)\n",
    "\n",
    "\n",
    "#creating a new cleaning function\n",
    "\n",
    "def clean_answer(s, patterns=['Answer:', ' ']):\n",
    "    result=str(s)\n",
    "    for pattern in patterns: \n",
    "         result = result.replace(pattern, '') \n",
    "    return result\n",
    "   \n",
    "\n",
    "df_x_filtered = df_x_less10['result'].apply(clean_answer)\n",
    "df_y_filtered = df_y_less10['result'].apply(clean_answer)\n",
    "df_z_filtered = df_z_less10['result'].apply(clean_answer)\n",
    "\n",
    "#getting rid of NotSure\n",
    "\n",
    "df_x_cleaned = df_x_filtered.drop(df_x_filtered[df_x_filtered == 'NotSure'].index)\n",
    "df_y_cleaned = df_y_filtered.drop(df_y_filtered[df_y_filtered == 'NotSure'].index)\n",
    "df_z_cleaned = df_z_filtered.drop(df_z_filtered[df_z_filtered == 'NotSure'].index)\n",
    "\n",
    "print(\"cleaned df_x\", df_x_cleaned.value_counts())\n",
    "print(\"cleaned df_y\", df_y_cleaned.value_counts())\n",
    "print(\"cleaned df_z\", df_z_cleaned.value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2415cd9b",
   "metadata": {},
   "source": [
    "C. /Discuss:/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "9361b637",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For df_x :\n",
      "the lengh of the original dataset is : 13882\n",
      "the lengh of the cleaned dataset is : 13436\n",
      "which gives us a ratio of : 0.9678720645440139\n",
      "For df_y :\n",
      "the lengh of the original dataset is : 13978\n",
      "the lengh of the cleaned dataset is : 13551\n",
      "which gives us a ratio of : 0.9694519959937044\n",
      "For df_z :\n",
      "the lengh of the original dataset is : 13923\n",
      "the lengh of the cleaned dataset is : 12753\n",
      "which gives us a ratio of : 0.9159663865546218\n"
     ]
    }
   ],
   "source": [
    "#let's compare the lenghts\n",
    "print('For df_x :')\n",
    "print ('the lengh of the original dataset is :', df_x.shape[0])\n",
    "print ('the lengh of the cleaned dataset is :', df_x_cleaned.shape[0])\n",
    "print ('which gives us a ratio of :', df_x_cleaned.shape[0]/df_x.shape[0])\n",
    "\n",
    "print('For df_y :')\n",
    "print ('the lengh of the original dataset is :', df_y.shape[0])\n",
    "print ('the lengh of the cleaned dataset is :', df_y_cleaned.shape[0])\n",
    "print ('which gives us a ratio of :', df_y_cleaned.shape[0]/df_y.shape[0])\n",
    "\n",
    "print('For df_z :')\n",
    "print ('the lengh of the original dataset is :', df_z.shape[0])\n",
    "print ('the lengh of the cleaned dataset is :', df_z_cleaned.shape[0])\n",
    "print ('which gives us a ratio of :', df_z_cleaned.shape[0]/df_z.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da1cf129-09dd-47b1-9737-2c4d57eb8853",
   "metadata": {},
   "source": [
    "### 1.4 (3 pt)\n",
    "\n",
    "Now that our answer columns are nicely formatted, let's take a look at model performance:\n",
    "\n",
    "A. Both the `MMLU` dataframes and the language model score data frames have the columns `question_id`. For each of the language model score data frames, use an inner join operation with the `df_test` dataframe on the `question_id` column.\n",
    "\n",
    "B. Add a new column to each of the resulting dataframes called `correct`, that checks if the model's answer in `result` is the same as the expected answer in the column `answer`. Then, print the average score of each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "e66b36f3-f5a4-4237-9b48-39b21716d7aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>result</th>\n",
       "      <th>question</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>answer</th>\n",
       "      <th>subject</th>\n",
       "      <th>question_id</th>\n",
       "      <th>correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B</td>\n",
       "      <td>Find the degree for the given field extension ...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>B</td>\n",
       "      <td>abstract algebra</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C</td>\n",
       "      <td>Let p = (1, 2, 5, 4)(2, 3) in S_5 . Find the i...</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "      <td>120</td>\n",
       "      <td>C</td>\n",
       "      <td>abstract algebra</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>D</td>\n",
       "      <td>Find all zeros in the indicated finite field o...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0,1</td>\n",
       "      <td>0,4</td>\n",
       "      <td>D</td>\n",
       "      <td>abstract algebra</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B</td>\n",
       "      <td>Statement 1 | A factor group of a non-Abelian ...</td>\n",
       "      <td>True, True</td>\n",
       "      <td>False, False</td>\n",
       "      <td>True, False</td>\n",
       "      <td>False, True</td>\n",
       "      <td>B</td>\n",
       "      <td>abstract algebra</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B</td>\n",
       "      <td>Find the product of the given polynomials in t...</td>\n",
       "      <td>2x^2 + 5</td>\n",
       "      <td>6x^2 + 4x + 6</td>\n",
       "      <td>0</td>\n",
       "      <td>x^2 + 1</td>\n",
       "      <td>B</td>\n",
       "      <td>abstract algebra</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13877</th>\n",
       "      <td>A</td>\n",
       "      <td>Guru Nanak used what term to denote the \"divi...</td>\n",
       "      <td>Shabad</td>\n",
       "      <td>Khalse</td>\n",
       "      <td>Nam</td>\n",
       "      <td>Guru</td>\n",
       "      <td>A</td>\n",
       "      <td>world religions</td>\n",
       "      <td>13877</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13878</th>\n",
       "      <td>A</td>\n",
       "      <td>What is the mi'raj?</td>\n",
       "      <td>Muhammad's miraculous ascent to heaven</td>\n",
       "      <td>Muhammad's migration to Mecca</td>\n",
       "      <td>Muhammad's first community in Mecca</td>\n",
       "      <td>Muhammad's revelations of the Qur'an</td>\n",
       "      <td>A</td>\n",
       "      <td>world religions</td>\n",
       "      <td>13878</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13879</th>\n",
       "      <td>B</td>\n",
       "      <td>What is the name of the most famous dharmashas...</td>\n",
       "      <td>Laws of Dharma</td>\n",
       "      <td>Laws of Karma</td>\n",
       "      <td>Laws of Vishnu</td>\n",
       "      <td>Laws of Manu</td>\n",
       "      <td>D</td>\n",
       "      <td>world religions</td>\n",
       "      <td>13879</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13880</th>\n",
       "      <td>B</td>\n",
       "      <td>What does the term \"Qur'an\" literally mean?</td>\n",
       "      <td>The Holy Book</td>\n",
       "      <td>The Narrative</td>\n",
       "      <td>The Recitation</td>\n",
       "      <td>The Pillars</td>\n",
       "      <td>C</td>\n",
       "      <td>world religions</td>\n",
       "      <td>13880</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13881</th>\n",
       "      <td>A</td>\n",
       "      <td>Mani referred to God by which of the followin...</td>\n",
       "      <td>Mother of Light</td>\n",
       "      <td>Father of Goodness</td>\n",
       "      <td>Ineffable Lover</td>\n",
       "      <td>Eternal Spirit</td>\n",
       "      <td>B</td>\n",
       "      <td>world religions</td>\n",
       "      <td>13881</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13436 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      result                                           question  \\\n",
       "0          B  Find the degree for the given field extension ...   \n",
       "1          C  Let p = (1, 2, 5, 4)(2, 3) in S_5 . Find the i...   \n",
       "2          D  Find all zeros in the indicated finite field o...   \n",
       "3          B  Statement 1 | A factor group of a non-Abelian ...   \n",
       "4          B  Find the product of the given polynomials in t...   \n",
       "...      ...                                                ...   \n",
       "13877      A   Guru Nanak used what term to denote the \"divi...   \n",
       "13878      A                                What is the mi'raj?   \n",
       "13879      B  What is the name of the most famous dharmashas...   \n",
       "13880      B        What does the term \"Qur'an\" literally mean?   \n",
       "13881      A   Mani referred to God by which of the followin...   \n",
       "\n",
       "                                            A                              B  \\\n",
       "0                                           0                              4   \n",
       "1                                           8                              2   \n",
       "2                                           0                              1   \n",
       "3                                  True, True                   False, False   \n",
       "4                                    2x^2 + 5                  6x^2 + 4x + 6   \n",
       "...                                       ...                            ...   \n",
       "13877                                  Shabad                         Khalse   \n",
       "13878  Muhammad's miraculous ascent to heaven  Muhammad's migration to Mecca   \n",
       "13879                          Laws of Dharma                  Laws of Karma   \n",
       "13880                           The Holy Book                  The Narrative   \n",
       "13881                         Mother of Light             Father of Goodness   \n",
       "\n",
       "                                         C  \\\n",
       "0                                        2   \n",
       "1                                       24   \n",
       "2                                      0,1   \n",
       "3                              True, False   \n",
       "4                                        0   \n",
       "...                                    ...   \n",
       "13877                                  Nam   \n",
       "13878  Muhammad's first community in Mecca   \n",
       "13879                       Laws of Vishnu   \n",
       "13880                       The Recitation   \n",
       "13881                      Ineffable Lover   \n",
       "\n",
       "                                          D answer           subject  \\\n",
       "0                                         6      B  abstract algebra   \n",
       "1                                       120      C  abstract algebra   \n",
       "2                                       0,4      D  abstract algebra   \n",
       "3                               False, True      B  abstract algebra   \n",
       "4                                   x^2 + 1      B  abstract algebra   \n",
       "...                                     ...    ...               ...   \n",
       "13877                                  Guru      A   world religions   \n",
       "13878  Muhammad's revelations of the Qur'an      A   world religions   \n",
       "13879                          Laws of Manu      D   world religions   \n",
       "13880                           The Pillars      C   world religions   \n",
       "13881                        Eternal Spirit      B   world religions   \n",
       "\n",
       "       question_id  correct  \n",
       "0                0     True  \n",
       "1                1     True  \n",
       "2                2     True  \n",
       "3                3     True  \n",
       "4                4     True  \n",
       "...            ...      ...  \n",
       "13877        13877     True  \n",
       "13878        13878     True  \n",
       "13879        13879    False  \n",
       "13880        13880    False  \n",
       "13881        13881    False  \n",
       "\n",
       "[13436 rows x 10 columns]"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A\n",
    "df_x_cleaned_df = df_x_cleaned.to_frame(name= 'result').rename_axis('question_id')\n",
    "merged_x_df = df_x_cleaned_df.merge(df_test, left_index=True, right_on='question_id')\n",
    "\n",
    "#B\n",
    "merged_x_df['correct'] = merged_x_df['result'] == merged_x_df['answer']\n",
    "merged_x_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "c5ba4442",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "correct\n",
       "False    8871\n",
       "True     4565\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_x_df['correct'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "21049f29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>result</th>\n",
       "      <th>question</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>answer</th>\n",
       "      <th>subject</th>\n",
       "      <th>question_id</th>\n",
       "      <th>correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>D</td>\n",
       "      <td>Find the degree for the given field extension ...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>B</td>\n",
       "      <td>abstract algebra</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D</td>\n",
       "      <td>Let p = (1, 2, 5, 4)(2, 3) in S_5 . Find the i...</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "      <td>120</td>\n",
       "      <td>C</td>\n",
       "      <td>abstract algebra</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>D</td>\n",
       "      <td>Find all zeros in the indicated finite field o...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0,1</td>\n",
       "      <td>0,4</td>\n",
       "      <td>D</td>\n",
       "      <td>abstract algebra</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>D</td>\n",
       "      <td>Find the product of the given polynomials in t...</td>\n",
       "      <td>2x^2 + 5</td>\n",
       "      <td>6x^2 + 4x + 6</td>\n",
       "      <td>0</td>\n",
       "      <td>x^2 + 1</td>\n",
       "      <td>B</td>\n",
       "      <td>abstract algebra</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>C</td>\n",
       "      <td>Statement 1 | If a group has an element of ord...</td>\n",
       "      <td>True, True</td>\n",
       "      <td>False, False</td>\n",
       "      <td>True, False</td>\n",
       "      <td>False, True</td>\n",
       "      <td>A</td>\n",
       "      <td>abstract algebra</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13973</th>\n",
       "      <td>C</td>\n",
       "      <td>What is the term used to describe the \"pure\" ...</td>\n",
       "      <td>Khalsa</td>\n",
       "      <td>Rahit</td>\n",
       "      <td>Panj Kakke</td>\n",
       "      <td>Shabad</td>\n",
       "      <td>A</td>\n",
       "      <td>world religions</td>\n",
       "      <td>13973</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13974</th>\n",
       "      <td>D</td>\n",
       "      <td>Who is the founder of Sikhism?</td>\n",
       "      <td>Guru Gobind Singh</td>\n",
       "      <td>Guru Nanak</td>\n",
       "      <td>Guru Kabir</td>\n",
       "      <td>Guru Hargobind</td>\n",
       "      <td>B</td>\n",
       "      <td>world religions</td>\n",
       "      <td>13974</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13975</th>\n",
       "      <td>D</td>\n",
       "      <td>Which term is usually associated with women in...</td>\n",
       "      <td>Polluted</td>\n",
       "      <td>Ideal</td>\n",
       "      <td>Auspiciousness</td>\n",
       "      <td>Kind</td>\n",
       "      <td>C</td>\n",
       "      <td>world religions</td>\n",
       "      <td>13975</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13976</th>\n",
       "      <td>B</td>\n",
       "      <td>What is another name for Enuma Elish?</td>\n",
       "      <td>Epic of Creation</td>\n",
       "      <td>Epic of Destruction</td>\n",
       "      <td>Epic of Egypt</td>\n",
       "      <td>Epic of Origins</td>\n",
       "      <td>A</td>\n",
       "      <td>world religions</td>\n",
       "      <td>13976</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13977</th>\n",
       "      <td>D</td>\n",
       "      <td>What was the most important female-centered f...</td>\n",
       "      <td>Thesmophoria</td>\n",
       "      <td>Oracle Days</td>\n",
       "      <td>Isthmian Games</td>\n",
       "      <td>Feast of Athrodite</td>\n",
       "      <td>A</td>\n",
       "      <td>world religions</td>\n",
       "      <td>13977</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13551 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      result                                           question  \\\n",
       "0          D  Find the degree for the given field extension ...   \n",
       "1          D  Let p = (1, 2, 5, 4)(2, 3) in S_5 . Find the i...   \n",
       "2          D  Find all zeros in the indicated finite field o...   \n",
       "4          D  Find the product of the given polynomials in t...   \n",
       "5          C  Statement 1 | If a group has an element of ord...   \n",
       "...      ...                                                ...   \n",
       "13973      C   What is the term used to describe the \"pure\" ...   \n",
       "13974      D                     Who is the founder of Sikhism?   \n",
       "13975      D  Which term is usually associated with women in...   \n",
       "13976      B              What is another name for Enuma Elish?   \n",
       "13977      D   What was the most important female-centered f...   \n",
       "\n",
       "                       A                    B               C  \\\n",
       "0                      0                    4               2   \n",
       "1                      8                    2              24   \n",
       "2                      0                    1             0,1   \n",
       "4               2x^2 + 5        6x^2 + 4x + 6               0   \n",
       "5             True, True         False, False     True, False   \n",
       "...                  ...                  ...             ...   \n",
       "13973             Khalsa                Rahit      Panj Kakke   \n",
       "13974  Guru Gobind Singh           Guru Nanak      Guru Kabir   \n",
       "13975           Polluted                Ideal  Auspiciousness   \n",
       "13976   Epic of Creation  Epic of Destruction   Epic of Egypt   \n",
       "13977       Thesmophoria          Oracle Days  Isthmian Games   \n",
       "\n",
       "                        D answer           subject  question_id  correct  \n",
       "0                       6      B  abstract algebra            0    False  \n",
       "1                     120      C  abstract algebra            1    False  \n",
       "2                     0,4      D  abstract algebra            2     True  \n",
       "4                 x^2 + 1      B  abstract algebra            4    False  \n",
       "5             False, True      A  abstract algebra            5    False  \n",
       "...                   ...    ...               ...          ...      ...  \n",
       "13973              Shabad      A   world religions        13973    False  \n",
       "13974      Guru Hargobind      B   world religions        13974    False  \n",
       "13975                Kind      C   world religions        13975    False  \n",
       "13976     Epic of Origins      A   world religions        13976    False  \n",
       "13977  Feast of Athrodite      A   world religions        13977    False  \n",
       "\n",
       "[13551 rows x 10 columns]"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_y_cleaned_df = df_y_cleaned.to_frame(name= 'result').rename_axis('question_id')\n",
    "merged_y_df = df_y_cleaned_df.merge(df_test, left_index=True, right_on='question_id')\n",
    "\n",
    "#B\n",
    "merged_y_df['correct'] = merged_y_df['result'] == merged_y_df['answer']\n",
    "merged_y_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "aef9e949",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>result</th>\n",
       "      <th>question</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>answer</th>\n",
       "      <th>subject</th>\n",
       "      <th>question_id</th>\n",
       "      <th>correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B</td>\n",
       "      <td>Find the degree for the given field extension ...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>B</td>\n",
       "      <td>abstract algebra</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B</td>\n",
       "      <td>Let p = (1, 2, 5, 4)(2, 3) in S_5 . Find the i...</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "      <td>120</td>\n",
       "      <td>C</td>\n",
       "      <td>abstract algebra</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C</td>\n",
       "      <td>Find all zeros in the indicated finite field o...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0,1</td>\n",
       "      <td>0,4</td>\n",
       "      <td>D</td>\n",
       "      <td>abstract algebra</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B</td>\n",
       "      <td>Statement 1 | A factor group of a non-Abelian ...</td>\n",
       "      <td>True, True</td>\n",
       "      <td>False, False</td>\n",
       "      <td>True, False</td>\n",
       "      <td>False, True</td>\n",
       "      <td>B</td>\n",
       "      <td>abstract algebra</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B</td>\n",
       "      <td>Find the product of the given polynomials in t...</td>\n",
       "      <td>2x^2 + 5</td>\n",
       "      <td>6x^2 + 4x + 6</td>\n",
       "      <td>0</td>\n",
       "      <td>x^2 + 1</td>\n",
       "      <td>B</td>\n",
       "      <td>abstract algebra</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13918</th>\n",
       "      <td>A</td>\n",
       "      <td>The Maccabean Revolt is associated with which...</td>\n",
       "      <td>Julius Caesar</td>\n",
       "      <td>Alexander the Great</td>\n",
       "      <td>Cyrus of Persia</td>\n",
       "      <td>Antiochus IV Epiphanes</td>\n",
       "      <td>D</td>\n",
       "      <td>world religions</td>\n",
       "      <td>13918</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13919</th>\n",
       "      <td>A</td>\n",
       "      <td>How old was Guru Nanak when he started to pre...</td>\n",
       "      <td>30</td>\n",
       "      <td>40</td>\n",
       "      <td>33</td>\n",
       "      <td>52</td>\n",
       "      <td>A</td>\n",
       "      <td>world religions</td>\n",
       "      <td>13919</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13920</th>\n",
       "      <td>B</td>\n",
       "      <td>The widely adored Egyptian goddess Hathor was ...</td>\n",
       "      <td>Serpent</td>\n",
       "      <td>Eagle</td>\n",
       "      <td>Cheetah</td>\n",
       "      <td>Cow</td>\n",
       "      <td>D</td>\n",
       "      <td>world religions</td>\n",
       "      <td>13920</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13921</th>\n",
       "      <td>B</td>\n",
       "      <td>What does the phrase Guru-Panth mean within th...</td>\n",
       "      <td>Community</td>\n",
       "      <td>Scripture</td>\n",
       "      <td>Worship</td>\n",
       "      <td>Apprenticeship</td>\n",
       "      <td>A</td>\n",
       "      <td>world religions</td>\n",
       "      <td>13921</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13922</th>\n",
       "      <td>A</td>\n",
       "      <td>After what event did the Rabbinical period be...</td>\n",
       "      <td>Construction of the Second Temple</td>\n",
       "      <td>Destruction of the Second Temple</td>\n",
       "      <td>The Christianization of the Roman Empire</td>\n",
       "      <td>The emergence of Islam</td>\n",
       "      <td>B</td>\n",
       "      <td>world religions</td>\n",
       "      <td>13922</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12753 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      result                                           question  \\\n",
       "0          B  Find the degree for the given field extension ...   \n",
       "1          B  Let p = (1, 2, 5, 4)(2, 3) in S_5 . Find the i...   \n",
       "2          C  Find all zeros in the indicated finite field o...   \n",
       "3          B  Statement 1 | A factor group of a non-Abelian ...   \n",
       "4          B  Find the product of the given polynomials in t...   \n",
       "...      ...                                                ...   \n",
       "13918      A   The Maccabean Revolt is associated with which...   \n",
       "13919      A   How old was Guru Nanak when he started to pre...   \n",
       "13920      B  The widely adored Egyptian goddess Hathor was ...   \n",
       "13921      B  What does the phrase Guru-Panth mean within th...   \n",
       "13922      A   After what event did the Rabbinical period be...   \n",
       "\n",
       "                                       A                                 B  \\\n",
       "0                                      0                                 4   \n",
       "1                                      8                                 2   \n",
       "2                                      0                                 1   \n",
       "3                             True, True                      False, False   \n",
       "4                               2x^2 + 5                     6x^2 + 4x + 6   \n",
       "...                                  ...                               ...   \n",
       "13918                      Julius Caesar               Alexander the Great   \n",
       "13919                                 30                                40   \n",
       "13920                            Serpent                             Eagle   \n",
       "13921                          Community                         Scripture   \n",
       "13922  Construction of the Second Temple  Destruction of the Second Temple   \n",
       "\n",
       "                                              C                       D  \\\n",
       "0                                             2                       6   \n",
       "1                                            24                     120   \n",
       "2                                           0,1                     0,4   \n",
       "3                                   True, False             False, True   \n",
       "4                                             0                 x^2 + 1   \n",
       "...                                         ...                     ...   \n",
       "13918                           Cyrus of Persia  Antiochus IV Epiphanes   \n",
       "13919                                        33                      52   \n",
       "13920                                   Cheetah                     Cow   \n",
       "13921                                   Worship          Apprenticeship   \n",
       "13922  The Christianization of the Roman Empire  The emergence of Islam   \n",
       "\n",
       "      answer           subject  question_id  correct  \n",
       "0          B  abstract algebra            0     True  \n",
       "1          C  abstract algebra            1    False  \n",
       "2          D  abstract algebra            2    False  \n",
       "3          B  abstract algebra            3     True  \n",
       "4          B  abstract algebra            4     True  \n",
       "...      ...               ...          ...      ...  \n",
       "13918      D   world religions        13918    False  \n",
       "13919      A   world religions        13919     True  \n",
       "13920      D   world religions        13920    False  \n",
       "13921      A   world religions        13921    False  \n",
       "13922      B   world religions        13922    False  \n",
       "\n",
       "[12753 rows x 10 columns]"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df_z_cleaned_df = df_z_cleaned.to_frame(name= 'result').rename_axis('question_id')\n",
    "merged_z_df=df_z_cleaned_df.merge(df_test, left_index=True, right_on='question_id')\n",
    "\n",
    "#B\n",
    "merged_z_df['correct'] = merged_z_df['result'] == merged_z_df['answer']\n",
    "merged_z_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "50b024d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33.97588568026198\n",
      "34.373846948564676\n",
      "31.812122637810713\n"
     ]
    }
   ],
   "source": [
    "# B - average score of each model\n",
    "print(merged_x_df['correct'].mean()* 100)\n",
    "print(merged_y_df['correct'].mean()* 100)\n",
    "print(merged_z_df['correct'].mean()* 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69decfd8-8083-4c2f-8263-a153d55efede",
   "metadata": {},
   "source": [
    "### 1.5 (5 pt)\n",
    "\n",
    "Hmmm, something doesn't seem quite right. Let's investigate how \"balanced\" this dataset is:\n",
    "\n",
    "A. For each of the 57 subjects in the MMLU, compare the number of questions answered by each model. Print the subjects for which there is a more than 10% difference.\n",
    "\n",
    "B. Propose and implement a reasonable way to rebalance the results. (e.g., while throwing away 100% of the results perfectly rebalances the results, it is not reasonable).\n",
    "\n",
    "C. Finally, print the updated accuracy on the rebalanced data.\n",
    "\n",
    "**hint:**:\n",
    "- (A) For a given subject, let model X and model Y have answered 181 and 200 questions respectively. You can consider this a 10% difference from the perspective of X since: (200 - 181) / 181 > 0.10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19463002-732b-405b-8b44-77f702bdb665",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb8c324",
   "metadata": {},
   "outputs": [],
   "source": [
    "# B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affc3746",
   "metadata": {},
   "outputs": [],
   "source": [
    "# C"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "292b2f61-0529-4b6d-a3a7-af786a4d79ae",
   "metadata": {},
   "source": [
    "## Task 2 (26 points): What do you mean A > D > B > C...?\n",
    "\n",
    "Nice work! Having successfully inspected, cleaned, and rebalanced the provided data, you head over to director of the government's NEUTRALITY project. Ms. Sakota is happy with your work so far, but worried that the sloppy intern might have done more undetected damage. To be sure, she orders a new set of evaluations of all models on both MMLU and another dataset.\n",
    "\n",
    "After cleaning up and rebalancing, you are left with the concatenated score files in the second folder `task_2`:\n",
    "```\n",
    "task_2/\n",
    "│\n",
    "└── lm_scores_mmlu.csv\n",
    "│\n",
    "└── lm_scores_other.csv\n",
    "```\n",
    "\n",
    "Each has a new column called `model_name`, which is one of `X, Y` or `Z`.\n",
    "\n",
    "\n",
    "\n",
    "_NOTE: **only** use data from `task_2` and `task_2_5` for this assignment! The values in `lm_scores_mmlu.csv` will NOT be the same as the dataframes you finished in task 1. This is due to \"randomness\" or \"temperature\" in language model inference. This can slightly shift around generative results. (Conveniently: it also ensures any mistakes made in Task 1 don't propogate further ;) )_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a889a76b-e034-4d2f-929e-0ef1f250a0a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PROVIDED CODE\n",
    "df_mmlu = pd.read_csv('task_2/lm_scores_mmlu.csv')\n",
    "df_other = pd.read_csv('task_2/lm_scores_other.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c31edde3-cc91-4d08-81c7-b5e98cf0ff9c",
   "metadata": {},
   "source": [
    "### 2.1 (4 pt)\n",
    "\n",
    "Let's explore the new results:\n",
    "\n",
    "A. Compute the mean accuracy and standard errors of each model on both datasets and print the results.\n",
    "\n",
    "B. Then, show your results in a bar plot using standard errors with a 95% confidence interval around the mean. Make sure the plot is easy to read and well annotated.\n",
    "\n",
    "C. /Discuss:/ the plot you created: (i) can you say that one of the models is the best? (ii) is there anything that seems odd?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56fe8cca-acd1-4f5e-a938-e8d3a850f220",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a176c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c9fbfe",
   "metadata": {},
   "source": [
    "C. /Discuss:/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eee0ec62-f2d1-4bae-a6f6-221320d602cb",
   "metadata": {},
   "source": [
    "### 2.2 (5 pt)\n",
    "\n",
    "Ms. Sakota has assured you that both datasets contain questions of similar difficulty, so, what could be going on here?\n",
    "\n",
    "A. What is the distribution of correct answers (A, B, C, D) for each dataset? Create a bar chart to visualize this.\n",
    "\n",
    "B. Perform a chi-square test at $\\alpha = 0.05$, of independence to determine if there's a significant difference in the distribution of correct answers between the two datasets. What do you conclude?\n",
    "\n",
    "**hints**:\n",
    "- for (A), keep in mind that df_mmlu and df_other contain the results of all models, i.e., the `question_id` column is duplicated.\n",
    "- for (A), take care to clearly annotate the bar chart, e.g., title, y-label, legend.\n",
    "- for (B), clearly state the null hypothesis and alternative hypothesis\n",
    "- use the `chi2_contingency` function from `scipy.stats`\n",
    "- format your results from answer (A) as a 2D array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b16f70-93e0-4a19-8a6d-b3ae5a75ae65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92392cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d3125ad-5a7e-44e7-999a-a0ff99855d39",
   "metadata": {},
   "source": [
    "### 2.3 (7 pt)\n",
    "\n",
    "Let's dive in deeper:\n",
    "\n",
    "A. What is language model X's mean accuracy conditioned on the four answer options for each dataset?\n",
    "\n",
    "B. Compare LM X's performance when the correct answer is \"A\" between the two datasets. Use a T-test with CI = 0.95. What do you conclude?\n",
    "\n",
    "C. Compare LM X's performance when the correct answer is \"A\" vs. \"C or D\" for each dataset. Use a T-test with CI = 0.95. What do you conclude?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39097a11-8efe-46d1-8bc3-5587bb58d199",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae67c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636af6a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# C"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33848ff9-2604-4e48-b5df-3207dc81e9a9",
   "metadata": {},
   "source": [
    "### 2.4 (2 pt)\n",
    "\n",
    "What an intriguing finding! \n",
    "\n",
    "A. Print the mean accuracies conditioned on the correct answer for all LMs for each dataset.\n",
    "\n",
    "B. /Discuss:/ What do you observe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec53ce2c-866e-440a-ac79-7813cb756782",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce58e47",
   "metadata": {},
   "source": [
    "B. /Discuss:/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccdd9d3c-5a03-4b30-84f7-a7dfbee1373e",
   "metadata": {},
   "source": [
    "### 2.5 (2 pt)\n",
    "\n",
    "Concerned with your findings so far, you quickly consult with Ms. Sakota. After thinking it over, Ms. Sakota concludes that more tests are needed. She orders a second round of MMLU results. However, the clever Ms. Sakota thinks of the following twist: while keeping questions fixed, she randomly permutes the position of the correct answer. The new results can be found in the folder `data/task_2_5/`:\n",
    "```\n",
    "task_2_5/\n",
    "│\n",
    "└── lm_scores_mmlu_shuffle.csv\n",
    "```\n",
    "\n",
    "/Discuss:/ Why would Ms. Sakota do this?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64cc586a",
   "metadata": {},
   "source": [
    "/Discuss:/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9150ae0-dbaa-4c88-bf80-ec03127c6945",
   "metadata": {},
   "source": [
    "### 2.6 (4 pt)\n",
    "\n",
    "Increasingly sceptical of the language models' performance, you read up on proper testing practices. You stumble upon the concept of [test-rested stability](https://en.wikipedia.org/wiki/Repeatability), which roughtly states that:\n",
    "\n",
    "\"_Measurements taken by a single person or instrument on the same item, under the same conditions, and in a short period of time, should have the same results._\"\n",
    "\n",
    "In our case, we would assume an LM would have the same performance on a given question regardless of the correct answer position. One way of testing this is by using the following metric:\n",
    "\n",
    "$$\\text{test-retest metric} = \\frac{1}{N}\\sum_{i=1}^N \\frac{1}{M}\\sum_{j=1}^M c^i_0 c_j^i,$$\n",
    "\n",
    "where $c^i_0 \\in \\{0, 1\\}$ indicates whether the model answers the $i^{\\text{th}}$ question correctly (1 if correct, 0 if incorrect). $c_j^i$ indicates whether the model answers the $i^{\\text{th}}$ question correctly in the $j^{\\text{th}}$ shuffled version of the answer label content. Finally, $M$ is the total number of shuffles and $N$ is the dataset size.\n",
    "\n",
    "Task: compute the test-retest metric for each language model using the original `lm_scores_mmlu.csv` file and the new `lm_scores_mmlu_shuffle.csv` file. Using a bar plot, visualize your results by comparing the accuracy of the original `lm_scores_mmlu.csv` and the test-retest scores.\n",
    "\n",
    "**hints**\n",
    "- what is $M$ in our case?\n",
    "\n",
    "(bonus: no points, but so much sweet, sweet knowledge - check out [the following article](https://arxiv.org/pdf/2406.19470v1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b55fcfc-6de9-4cd3-bf2d-bde399ae2fbc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b70bee6e-0c81-4f5a-b1a8-16a96aa2ae17",
   "metadata": {},
   "source": [
    "### 2.7 (2 pt)\n",
    "\n",
    "A. Using the unshuffled data: For each LM, print the distribution of the answers they give as well as the accuracy conditioned on the answer they give.\n",
    "\n",
    "B. /Discuss:/ Describe what you observe\n",
    "\n",
    "[bonus: not scored, but again _that sweet, sweet knowledge_] Could you think of a plausible explanation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4956581b-d047-46cb-ae71-1508a9a0b466",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65639228",
   "metadata": {},
   "source": [
    "B. /Discuss:/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce3186fe-ef8e-4af3-9a07-a6081d454e5a",
   "metadata": {},
   "source": [
    "## Task 3 (16 points): What do Questions and Answers look like for a Language Model?\n",
    "\n",
    "While you feel pretty good about the tests you conducted so far, something still bothers you: what if the language models don't see the data like you do? Suddenly, you receive a phone call from a wise AI sage in the West, _Westoda_:\n",
    "\n",
    "```\n",
    "\"Hmm, correct you are, young padawan, to question how the world is seen by large language models! Simple 'text' it is not, hmm? No, no, no! Characters and words, the way of puny humans, this is not, heh heh heh.\n",
    "\n",
    "'Tokens', they use, yes! Mysterious and powerful, these tokens are. Expand our vocabulary, they do, beyond the simple 'a to Z'. Chunky blocks of text, they become, yes! 'Hello world', a simple phrase it may seem. But to a language model, '[24912, 2375]' it might appear, yes! Confusing, it is, hmm?\n",
    "\n",
    "Wise, it would be, to explore these MMLU data points through the eyes of a language model, you think? Yes, yes! Much to learn, there is. The ways of the tokens, understand you must, if truly comprehend the great LMs, you wish to.\n",
    "Meditate on this, you should. The force of natural language processing, strong it is. But patience, you must have, my young padawan. For only through great study and contemplation, will the mysteries of the tokens reveal themselves to you, they will. Yes, hmmm!\"\n",
    "```\n",
    "\n",
    "Admittingly, Westoda at times speaks in riddles… However, he was explaining a crucial aspect of modern LMs called [Tokenization](https://learn.microsoft.com/en-us/dotnet/ai/conceptual/understanding-tokens):\n",
    "\n",
    "\n",
    "“Tokens are words, character sets, or combinations of words and punctuation that are used by [language models (LMs)] to decompose text into. Tokenization is the first step in training”\n",
    "\n",
    "Instead of characters, LMs process natural language using “tokens”. While this is useful for a number of reasons, it does at times introduce some “unintuitive” behavior…"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c66517-938b-4331-9eea-1b23fe4ad9e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PROVIDED CODE\n",
    "\n",
    "try:\n",
    "    import tiktoken\n",
    "except Exception as e:\n",
    "    print('installing tiktoken package')\n",
    "    \n",
    "    !pip install tiktoken\n",
    "    \n",
    "    import tiktoken\n",
    "\n",
    "def tokenize_text(s):\n",
    "    enc = tiktoken.encoding_for_model('gpt-4o')\n",
    "    tokens = enc.encode(str(s))\n",
    "    return tokens\n",
    "\n",
    "example_string = 'hello world'\n",
    "print(f'humans see: \"{example_string}\" --> language models see: {tokenize_text(example_string)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c8019ee-7d52-496f-afff-c96f2f9db08c",
   "metadata": {},
   "source": [
    "### 3.1 (5 pt)\n",
    "\n",
    "Use the provided code in the cell above to \"see the world through the eyes of a language model\":\n",
    "\n",
    "A. Tokenize the questions of the original MMLU data provided in task 1: `task_1/mmlu_data/test.csv` and plot the token distribution (the frequency of each token).\n",
    "\n",
    "B. Same as (A), but now for the answers in columns (columns \"A\", \"B\", \"C\", and \"D\").\n",
    "\n",
    "C. Isolate the tokens for the strings \"A\", \"B\", \"C\", and \"D\", then, for their occurances in both questions and answers, print their relative distribution to each other.\n",
    "\n",
    "**hint**\n",
    "- There are a _lot_ of tokens, consider using a cutoff point and log scale\n",
    "- For (c), they should sum to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a1e97b-3a31-41b1-a9c3-fb84cb1740d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe1f8be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd392df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# C"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a674929c-68e1-4cd8-97b3-efa0cdae4874",
   "metadata": {},
   "source": [
    "### 3.2 (3 pt)\n",
    "\n",
    "What if the number of \"A\", \"B\", \"C\", and \"D\" tokens in the question and answer pairs could influence a language model's decisions?\n",
    "\n",
    "A. For each combined question-answers pair, compute: \n",
    "1. the number of \"A\", \"B\", \"C\", and \"D\" tokens; and\n",
    "2. the total number of tokens.\n",
    "3. then, group by the \"correct\" answer and compute the mean frequency of A, B, C, and D tokens and the total number of tokens. \n",
    "4. finally, print your results\n",
    "\n",
    "B. /Discuss:/ What do you think of the hypothesis that the frequency of A, B, C, and D tokens could influence answers?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25419cc1-f058-4c51-a0aa-577272b8b578",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea8a279",
   "metadata": {},
   "source": [
    "B. /Discuss:/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af25ef95-d2ce-4112-87f7-8b0a52755e2a",
   "metadata": {},
   "source": [
    "### 3.3 (4 pt)\n",
    "\n",
    "Three of the most important considerations when deciding between language models are:\n",
    "\n",
    "Quality\n",
    "Costs\n",
    "Speed\n",
    "\n",
    "So far, much of your analysis has focused on quality. However, the government has indicated that they are quite concerned about both the total costs and speed as well. Specifically, it has been brought to their attention that a new `turbo` model has been launched! \n",
    "\n",
    "This model is both cheaper and faster than the models you evaluated so far. However, there is a catch: the context length* is much smaller than that of the other LMS. Namely, it can only process **300** tokens during inference. Meanwhile, the other models can process up to 100K tokens! \n",
    "\n",
    "*_The “context length” refers to the number of tokens that can be given to an LM as input._\n",
    "\n",
    "A. Are there subjects where using the cheaper model might be problematic? I.e., where part of the question and answer(s) might not fit completely in the context?\n",
    "\n",
    "B. /Discuss:/ Can you think of a strategy that would balance the needs of the government?\n",
    "\n",
    "**hint**:\n",
    "- An LM needs to have both the question and the different answer options in its context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a88a6fa3-2735-44d7-9944-076cc9f679ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47f8a44a",
   "metadata": {},
   "source": [
    "B. /Dicsuss:/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "110f07bf-558f-467c-8f66-d88db561d455",
   "metadata": {},
   "source": [
    "### 3.4 (4 pt)\n",
    "\n",
    "/Discuss:/ The time has come to give your final recommendation on the use of LMs in education to the government! Taking into account everything you analyzed in all the preceding tasks (1, 2, and 3), please write a short recommendation consisting of 4 bullet points discussing your concerns.\n",
    "\n",
    "**hint**\n",
    "- Try to use the MECE framework: _Mutually Exclusive Collectively Exhaustive_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "434a5fa5",
   "metadata": {},
   "source": [
    "/Discuss:/\n",
    "1. \n",
    "\n",
    "2. \n",
    "\n",
    "3. \n",
    "\n",
    "4. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ada",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
